{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Instruction tuning (Finetuning) using custom dataset on GPT2"]},{"cell_type":"markdown","metadata":{},"source":["## 00. Setup packages and import all reqired settings"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["import os\n","import getpass\n","#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n","#os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"  # Set the GPU 1 to use\n","#os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = getpass.getpass(\"Token:\") \n","#assert os.environ[\"HUGGING_FACE_HUB_TOKEN\"]"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17190,"status":"ok","timestamp":1699950672276,"user":{"displayName":"KyungTae Lim","userId":"06695996952901489598"},"user_tz":-540},"id":"zL7c0WGH7t5Q","outputId":"f9e1620a-0964-4207-ba4d-6ce8d318d49c"},"outputs":[],"source":["!pip install transformers datasets accelerate peft -qqq"]},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":9930,"status":"ok","timestamp":1699950743874,"user":{"displayName":"KyungTae Lim","userId":"06695996952901489598"},"user_tz":-540},"id":"ZFI8q2CR8kK4"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM # GPT2TokenizerFast, GPT2LMHeadModel\n","from datasets import load_dataset"]},{"cell_type":"markdown","metadata":{"id":"w2WSTm6n9FQm"},"source":["## 01. Data Load"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"executionInfo":{"elapsed":125840,"status":"ok","timestamp":1699950873914,"user":{"displayName":"KyungTae Lim","userId":"06695996952901489598"},"user_tz":-540},"id":"vmNkaM4v9DnI","outputId":"e79ea142-ca46-4182-89e8-2e3055243207"},"outputs":[],"source":["train_dataset = load_dataset('Aeala/ShareGPT_Vicuna_unfiltered', split=\"train[:5000]\")"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"slOFWiCy9XAM"},"outputs":[{"data":{"text/plain":["[{'from': 'human',\n","  'markdown': None,\n","  'text': None,\n","  'value': \"Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...\"},\n"," {'from': 'gpt',\n","  'markdown': None,\n","  'text': None,\n","  'value': \"Here are the main ideas of Jeff Walker's Product Launch Formula that can be applied by a growth marketing agency for their clients:\\n\\n1. Identify the target audience and their needs: Understand the ideal customer for the product or service, and create a messaging that resonates with them.\\n2. Pre-launch: Build anticipation and excitement for the launch by creating buzz, gathering testimonials and case studies, and using social media to create awareness.\\n3. Launch: Use a well-crafted launch sequence to maximize sales and conversions. This can include offering bonuses, creating scarcity, and using a deadline to create urgency.\\n4. Post-launch: Follow up with customers, gather feedback, and continue to provide value to keep them engaged and loyal.\\n5. Create a product suite: Once the initial product is successful, expand the offering by creating additional products or services that address other needs of the same audience.\\n6. Continual optimization: Continually monitor and optimize the launch process and product suite to improve results.\\n7. Build a community: Use the launch process to build a community of customers who are passionate about the product and can help spread the word.\\n8. Use automation: Use technology and automation to streamline the launch process and improve efficiency.\"},\n"," {'from': 'human',\n","  'markdown': None,\n","  'text': None,\n","  'value': \"Summarize the main ideas of Brendon Burchard's Experts Academy into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...\"},\n"," {'from': 'gpt',\n","  'markdown': None,\n","  'text': None,\n","  'value': \"Here are the main ideas of Brendon Burchard's Experts Academy that can be applied by a growth marketing agency for their clients:\\n\\n1. Identify your expertise: Define your area of expertise and create a unique value proposition that differentiates you from others.\\n2. Create a content strategy: Develop a content strategy that showcases your expertise and provides value to your audience. This can include blog posts, videos, podcasts, and social media content.\\n3. Build your audience: Use social media, advertising, and other channels to build your audience and increase your visibility.\\n4. Develop your products: Create products and services that align with your expertise and meet the needs of your audience. These can include digital products, courses, coaching, and consulting services.\\n5. Create a brand: Develop a strong brand that reflects your expertise and resonates with your audience.\\n6. Build authority: Establish yourself as an authority in your industry by speaking at events, publishing a book, or appearing on podcasts or TV shows.\\n7. Monetize your expertise: Develop a monetization strategy that leverages your expertise and products to generate revenue.\\n8. Build a team: As your business grows, build a team of experts to help you scale your business and provide excellent service to your clients.\\n9. Continual improvement: Continually improve your products, services, and marketing strategies to stay ahead of the competition and provide the best possible experience for your clients.\\n10. Focus on impact: Ultimately, focus on making a positive impact in the lives of your clients and using your expertise to make a difference in the world.\"},\n"," {'from': 'human',\n","  'markdown': None,\n","  'text': None,\n","  'value': 'What are the mental triggers in Jeff Walker\\'s Product Launch Formula and \"Launch\" book?'},\n"," {'from': 'gpt',\n","  'markdown': None,\n","  'text': None,\n","  'value': 'Here are the mental triggers described in Jeff Walker\\'s Product Launch Formula and \"Launch\" book:\\n\\n1. Scarcity: Creating a sense of urgency by limiting the availability of the product or service being launched.\\n2. Authority: Establishing oneself as an expert or authority in the industry to build credibility and trust with the audience.\\n3. Social proof: Using testimonials, case studies, and other forms of social proof to demonstrate the effectiveness and value of the product or service.\\n4. Reciprocity: Offering something of value to the audience before asking for a sale or commitment.\\n5. Likeability: Building a personal connection with the audience and creating a likable persona to increase the chances of a sale.\\n6. Anticipation: Building anticipation and excitement leading up to the launch to generate buzz and increase interest in the product or service.\\n7. Exclusivity: Creating a feeling of exclusivity by offering early access or special deals to a select group of people.\\n8. Belonging: Creating a sense of community or belonging among the audience to increase engagement and loyalty to the brand.\\n9. Storytelling: Using storytelling to connect with the audience on an emotional level and make the product or service more relatable and memorable.\\n\\nBy leveraging these mental triggers, businesses can create an effective product launch strategy that resonates with their target audience and drives sales and growth.'},\n"," {'from': 'human',\n","  'markdown': None,\n","  'text': None,\n","  'value': 'Write a summary of why scarcity and urgency are the strongest mental triggers and have been the driving force behind many of our best performing campaigns over the last 8 years.'},\n"," {'from': 'gpt',\n","  'markdown': None,\n","  'text': None,\n","  'value': \"Scarcity and urgency are two of the strongest mental triggers in marketing because they create a sense of exclusivity and importance around a product or service. By creating a sense of limited availability or a deadline for a promotion, businesses can motivate customers to take action and make a purchase before it's too late.\\n\\nOver the last eight years, many businesses have leveraged these triggers in their marketing campaigns to great success. Scarcity and urgency have been used to sell everything from digital products to physical goods and services, and have proven to be highly effective in driving conversions and increasing revenue.\\n\\nThis is because scarcity and urgency tap into the natural human desire for instant gratification and fear of missing out (FOMO). When customers believe that they may miss out on a valuable opportunity if they don't act quickly, they are more likely to take action and make a purchase.\\n\\nFurthermore, scarcity and urgency can be combined with other mental triggers, such as social proof and authority, to create even more powerful marketing campaigns. By demonstrating the popularity and effectiveness of a product or service, businesses can increase the perceived value and urgency of a promotion, leading to even more sales and revenue.\\n\\nOverall, scarcity and urgency are powerful mental triggers that have been proven to drive results in marketing campaigns. By leveraging these triggers, businesses can create a sense of urgency and exclusivity around their products or services, motivating customers to take action and make a purchase before it's too late.\"},\n"," {'from': 'human',\n","  'markdown': None,\n","  'text': None,\n","  'value': \"Summarize Russell Brunson's Perfect Webinar Script...\"},\n"," {'from': 'gpt',\n","  'markdown': None,\n","  'text': None,\n","  'value': \"Russell Brunson's Perfect Webinar Script is a framework for delivering webinars that are designed to sell a product or service. Here are the key components of the Perfect Webinar Script:\\n\\n1. Introduction: The webinar starts with an introduction that establishes the presenter's credibility and establishes the topic.\\n2. Story: The presenter then tells a personal story that is related to the topic and establishes a connection with the audience.\\n3. Content: The presenter provides valuable content related to the topic, demonstrating their expertise and building trust with the audience.\\n4. Offer: The presenter then introduces the product or service they are selling, explaining how it solves the audience's problem and providing social proof to support their claims.\\n5. Bonuses: The presenter offers bonuses to sweeten the deal and make the offer more enticing.\\n6. Scarcity: The presenter creates a sense of urgency by limiting the availability of the offer or including a deadline for purchase.\\n7. FAQs: The presenter answers common questions about the offer, addressing objections and building trust with the audience.\\n8. Closing: The presenter then delivers a clear call to action, directing the audience to take a specific action to purchase the product or service.\\n\\nOverall, the Perfect Webinar Script is designed to build trust with the audience, establish the presenter's credibility, and provide valuable content, while also creating a sense of urgency and scarcity around the offer being presented. By following this framework, businesses can use webinars as a powerful tool to sell their products and services to a targeted audience.\"},\n"," {'from': 'human',\n","  'markdown': None,\n","  'text': None,\n","  'value': 'Summarize the 6 human needs as Tony Robbins explains...'},\n"," {'from': 'gpt',\n","  'markdown': None,\n","  'text': None,\n","  'value': 'Tony Robbins describes six core human needs that drive our behaviors and motivations. These six needs are:\\n\\n1. Certainty: The need for safety, stability, and predictability. This includes the need for comfort, security, and control over our environment.\\n2. Variety: The need for novelty, excitement, and change. This includes the need for adventure, stimulation, and new experiences.\\n3. Significance: The need to feel important, special, and unique. This includes the need for recognition, achievement, and respect.\\n4. Connection: The need for social connection and love. This includes the need for intimacy, belonging, and friendship.\\n5. Growth: The need for personal growth and development. This includes the need for learning, self-improvement, and progress.\\n6. Contribution: The need to make a positive impact in the world. This includes the need to give back, help others, and make a difference.\\n\\nAccording to Tony Robbins, these six needs are universal and apply to all individuals. Each person may prioritize these needs differently, and may fulfill them in different ways, but they are fundamental drivers of human behavior. By understanding these needs, individuals can gain insight into their own motivations and behaviors, and can use this knowledge to create a more fulfilling and meaningful life.'}]"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset[0][\"conversations\"]"]},{"cell_type":"markdown","metadata":{"id":"sZ2X14eq_XvG"},"source":["## 02. Load Tokenizer Setup"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":875,"status":"ok","timestamp":1699951577964,"user":{"displayName":"KyungTae Lim","userId":"06695996952901489598"},"user_tz":-540},"id":"FBcIMSrU-FtD"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"markdown","metadata":{},"source":["## 03. Preprocessing (Tokenization and Preprocessing for Causal Language Modeling)"]},{"cell_type":"markdown","metadata":{},"source":["### 03-1. Tokenize for all samples"]},{"cell_type":"code","execution_count":64,"metadata":{"executionInfo":{"elapsed":374,"status":"ok","timestamp":1699951932656,"user":{"displayName":"KyungTae Lim","userId":"06695996952901489598"},"user_tz":-540},"id":"jfk1j_U3AzYW"},"outputs":[],"source":["def tokenizer_fuction(samples):\n","  sample = samples[\"conversations\"]\n","  result = \"\"\n","  for sample in sample:\n","    if sample[\"from\"] == \"human\":\n","      result = result + \"USER: \" + sample[\"value\"] + \" \\n\"\n","    else:\n","      result = result + \"CHATBOT: \" + sample[\"value\"] + \" \\n\"\n","\n","  return tokenizer(result, padding=\"max_length\", truncation=True, max_length=256)"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49},"executionInfo":{"elapsed":7609,"status":"ok","timestamp":1699951949924,"user":{"displayName":"KyungTae Lim","userId":"06695996952901489598"},"user_tz":-540},"id":"y4La83npBvm0","outputId":"f8b5c21f-226e-4366-969b-dfe73aac2c20"},"outputs":[],"source":["tokenized_dataset = train_dataset.map(\n","    tokenizer_fuction,\n","    remove_columns=[\"conversations\", \"id\"]\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### 03-2. Data Preperation for Causal Language Modeling (next token prediction)"]},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699952056155,"user":{"displayName":"KyungTae Lim","userId":"06695996952901489598"},"user_tz":-540},"id":"7ackCgIgCEVT"},"outputs":[],"source":["from transformers import DataCollatorForLanguageModeling\n","collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"]},{"cell_type":"markdown","metadata":{},"source":["## 04. Load Pretrained Model and Generate sentences in initial settings"]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":3419,"status":"ok","timestamp":1699952065858,"user":{"displayName":"KyungTae Lim","userId":"06695996952901489598"},"user_tz":-540},"id":"lBD0pi05CdlT"},"outputs":[{"data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["model = AutoModelForCausalLM.from_pretrained('gpt2')\n","model"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"data":{"text/plain":["0.510342192"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["model.get_memory_footprint()/1000000000"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11664,"status":"ok","timestamp":1699952114352,"user":{"displayName":"KyungTae Lim","userId":"06695996952901489598"},"user_tz":-540},"id":"8nlHV3iECjrF","outputId":"4ee56f09-df7a-4601-8172-c281e444856b"},"outputs":[],"source":["def gen_function(prompt, model, tokenizer):\n","\n","    # 1) Prompt\n","    input_text = prompt\n","    # 2) Tokenizing and Tensor transformation\n","    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n","    input_ids = input_ids.to('cuda')\n","    # 3) Generate texts\n","    max_length = 100\n","    model = model.to(\"cuda\")\n","    sample_outputs = model.generate(input_ids, do_sample=True, max_length=max_length, temperature=0.7)\n","    # 4) Decoding texts\n","    return tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Could you give me some examples of Numpy array?\n","\n","I can't remember what Numpy had to do with arrays except it was not really a problem at all. (One of the coolest things about Numpy is that it is not only a great programming language but also an awesome library!)\n","\n","I can't remember what Numpy had to do with arrays except it was not really a problem at all. (One of the coolest things about Numpy is that it is not only a\n"]}],"source":["output = gen_function(\"Could you give me some examples of Numpy array?\", model, tokenizer)\n","print(output)"]},{"cell_type":"markdown","metadata":{},"source":["## 05. Train with Trainer and TrainingArguments"]},{"cell_type":"code","execution_count":71,"metadata":{"executionInfo":{"elapsed":365,"status":"ok","timestamp":1699952131157,"user":{"displayName":"KyungTae Lim","userId":"06695996952901489598"},"user_tz":-540},"id":"FYaIzCG_CSIy"},"outputs":[],"source":["from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","\toutput_dir=\"./gpt2_instruction_tuning\",\n","\toverwrite_output_dir=True,\n","\tnum_train_epochs=1,\n","\tper_device_train_batch_size=8,\n","\tsave_steps=1000,\n","\tsave_total_limit=2,\n",")"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":516,"status":"ok","timestamp":1699952132760,"user":{"displayName":"KyungTae Lim","userId":"06695996952901489598"},"user_tz":-540},"id":"MPqngg_HCVpa"},"outputs":[{"name":"stderr","output_type":"stream","text":["Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"]}],"source":["trainer = Trainer(\n","\tmodel=model,\n","\targs=training_args,\n","\tdata_collator=collator,\n","\ttrain_dataset=tokenized_dataset,\n",")"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":113},"id":"0TKbOAP9_gUM"},"outputs":[{"name":"stderr","output_type":"stream","text":["You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [625/625 01:33, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.452500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=625, training_loss=2.439342578125, metrics={'train_runtime': 94.2928, 'train_samples_per_second': 53.026, 'train_steps_per_second': 6.628, 'total_flos': 653230080000000.0, 'train_loss': 2.439342578125, 'epoch': 1.0})"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"9AoZsP7PCxW5"},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Could you give me some examples of Numpy array? You can make some of them (or use Numpy arrays) and you can use the `array` keyword.\n","\n","Let's first create a Numpy array. Here is an example of how it could work:\n","```\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","# Make a Numpy array of 4 elements\n","# Create an array\n","array = np.array([1,\n"]}],"source":["output = gen_function(\"Could you give me some examples of Numpy array?\", model, tokenizer)\n","print(output)"]},{"cell_type":"markdown","metadata":{},"source":["## 06. Quantization"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["model_name = \"gpt2\"\n","model_quant = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    device_map=\"auto\",\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant = True,\n","    trust_remote_code=True\n",")"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"data":{"text/plain":["0.134060568"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["model_quant.get_memory_footprint()/1000000000"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Give me some Numpy codes? I wanted to learn them.\n","\n","I'd like to put my own to be a great example.\n","\n","I want you to enjoy this. I want you to know that you want your own and not the other.\n","\n","I want you to be able to use this code to build your own.\n","\n","When I came up with the idea of a class with a public class I wanted it to be a nice structure that could be used by people.\n","\n","I looked at a bunch of code, and some that came up with public classes, and the other ones I tried to use as well.\n","\n","And finally I built it with classes and then I defined classes, and then I used a couple of others.\n","\n","And I wrote a class on what I wanted to do with the code, and I got it just right.\n","\n","And now here's what I've decided:\n","\n","All I've changed is that I have a\n"]}],"source":["max_length = 200\n","input_ids = tokenizer(\"Give me some Numpy codes?\", return_tensors=\"pt\").input_ids\n","sample_outputs = model_quant.generate(input_ids.to(\"cuda\"), do_sample=True, max_length=max_length, temperature=0.75)\n","print(tokenizer.decode(sample_outputs[0], skip_special_tokens=True))"]},{"cell_type":"markdown","metadata":{},"source":[" - Quantized model can not be trainable becuase the optimizer can't handle 4bit types of computation"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"]},{"ename":"ValueError","evalue":"You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m/home/ktlim/projects/AdvancedNLP/13. Instruction Tuning/code/02-1. Instruction Tuning on GPT2-Quantization.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B117.17.185.27/home/ktlim/projects/AdvancedNLP/13.%20Instruction%20Tuning/code/02-1.%20Instruction%20Tuning%20on%20GPT2-Quantization.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B117.17.185.27/home/ktlim/projects/AdvancedNLP/13.%20Instruction%20Tuning/code/02-1.%20Instruction%20Tuning%20on%20GPT2-Quantization.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \tmodel\u001b[39m=\u001b[39;49mmodel_quant,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B117.17.185.27/home/ktlim/projects/AdvancedNLP/13.%20Instruction%20Tuning/code/02-1.%20Instruction%20Tuning%20on%20GPT2-Quantization.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \targs\u001b[39m=\u001b[39;49mtraining_args,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B117.17.185.27/home/ktlim/projects/AdvancedNLP/13.%20Instruction%20Tuning/code/02-1.%20Instruction%20Tuning%20on%20GPT2-Quantization.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \tdata_collator\u001b[39m=\u001b[39;49mcollator,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B117.17.185.27/home/ktlim/projects/AdvancedNLP/13.%20Instruction%20Tuning/code/02-1.%20Instruction%20Tuning%20on%20GPT2-Quantization.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \ttrain_dataset\u001b[39m=\u001b[39;49mtokenized_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B117.17.185.27/home/ktlim/projects/AdvancedNLP/13.%20Instruction%20Tuning/code/02-1.%20Instruction%20Tuning%20on%20GPT2-Quantization.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\n","File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.9/site-packages/transformers/trainer.py:407\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39m# At this stage the model is already loaded\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[39mif\u001b[39;00m _is_quantized_and_base_model \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_peft_model:\n\u001b[0;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m for more details\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m     )\n\u001b[1;32m    412\u001b[0m \u001b[39melif\u001b[39;00m _is_quantized_and_base_model \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39m_is_quantized_training_enabled\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    414\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe model you want to train is loaded in 8-bit precision.  if you want to fine-tune an 8-bit\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m model, please make sure that you have installed `bitsandbytes>=0.37.0`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details"]}],"source":["trainer = Trainer(\n","\tmodel=model_quant,\n","\targs=training_args,\n","\tdata_collator=collator,\n","\ttrain_dataset=tokenized_dataset,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## 07. Training with LoRA Adaptor\n"," - We can load the GPT2 pretrained model with 4bit and freeze all parameters\n"," - Then add up just a LoRA adapter which is a small trainable layer\n"," - Finally we can tune Large LLM by training only the LoRA adapter "]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["from peft import LoraConfig, PeftModel, PeftConfig, TaskType, get_peft_model\n","import torch"]},{"cell_type":"markdown","metadata":{},"source":["### 07-1. Quanitzation using BitsAndBytes"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[],"source":["\n","from transformers import BitsAndBytesConfig\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### 07-2. Load model with 4bit using BitsAndBytes"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["model_quant_lora = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    trust_remote_code=True\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### 07-3. Set LoRA config"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["#Set Lora settings\n","lora_alpha = 6\n","lora_dropout = 0.2\n","r = 6\n","#target_module = [\"lm_head\",]\n","#module_to_save\n","peft_config = LoraConfig(\n","    lora_alpha=lora_alpha,\n","    lora_dropout=lora_dropout,\n","    r=r,\n","    bias=\"none\",\n","    task_type=TaskType.CAUSAL_LM,\n","    #target_modules=target_module\n",")"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"data":{"text/plain":["LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=6, target_modules=None, lora_alpha=6, lora_dropout=0.2, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={})"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["peft_config"]},{"cell_type":"markdown","metadata":{},"source":["### 07-4. Load model with LoRA adaptor"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[],"source":["model_quant_lora = get_peft_model(model=model_quant_lora, peft_config=peft_config)"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 221,184 || all params: 124,660,992 || trainable%: 0.1774283971685385\n"]}],"source":["model_quant_lora.print_trainable_parameters()"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): GPT2LMHeadModel(\n","      (transformer): GPT2Model(\n","        (wte): Embedding(50257, 768)\n","        (wpe): Embedding(1024, 768)\n","        (drop): Dropout(p=0.1, inplace=False)\n","        (h): ModuleList(\n","          (0-11): 12 x GPT2Block(\n","            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (attn): GPT2Attention(\n","              (c_attn): Linear4bit(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.2, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=768, out_features=6, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=6, out_features=2304, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear4bit(in_features=768, out_features=2304, bias=True)\n","              )\n","              (c_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n","              (attn_dropout): Dropout(p=0.1, inplace=False)\n","              (resid_dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (mlp): GPT2MLP(\n","              (c_fc): Linear4bit(in_features=768, out_features=3072, bias=True)\n","              (c_proj): Linear4bit(in_features=3072, out_features=768, bias=True)\n","              (act): NewGELUActivation()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n","    )\n","  )\n",")"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["model_quant_lora"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["from transformers import Trainer, TrainingArguments\n","\n","per_device_train_batch_size = 4\n","gradient_accumulation_steps = 4\n","optim = \"paged_adamw_32bit\"\n","save_steps = 10\n","out_dir = \"./my-gpt2-output\"\n","\n","train_arg = TrainingArguments(\n","    output_dir=out_dir,\n","    num_train_epochs=1,\n","    per_device_eval_batch_size=per_device_train_batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    optim=optim,\n","    save_steps=save_steps,\n","    fp16=True,\n","    group_by_length=True\n",")"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"]}],"source":["max_seq_length = 512\n","\n","trainer = Trainer(\n","\tmodel=model_quant_lora,\n","\targs=training_args,\n","\tdata_collator=collator,\n","\ttrain_dataset=tokenized_dataset,\n",")"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [625/625 00:50, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.770600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=625, training_loss=2.7597544921875, metrics={'train_runtime': 50.8508, 'train_samples_per_second': 98.327, 'train_steps_per_second': 12.291, 'total_flos': 654928773120000.0, 'train_loss': 2.7597544921875, 'epoch': 1.0})"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Who is Brack Obama?\n","\n","Well, Brack Obama is obviously the most popular president in recent history. It's the first time in history that a president has been elected president with a national popular vote.\n","\n","The most popular president was Lyndon Johnson, who was the first African-American president. Since that time, President Obama has been the most popular president in history. As an African-American, Obama has had an extremely negative campaign environment. To put it in perspective, if you're a Republican and you're in the Democrat, you can be a Republican and a Democrat.\n","\n","This isn't the first time that the Democratic Party has had a negative campaign environment. A lot of people are saying that Democrats are bad, especially when it comes to foreign policy. But that's because we're not in the Republican Party anymore.\n","\n","The other major political parties in the United States have had much less negative campaigns than the Republicans, but the Democratic Party is still in the Republican\n"]}],"source":["max_length = 200\n","input_ids = tokenizer(\"Who is Brack Obama?\", return_tensors=\"pt\")\n","sample_outputs = model_quant_lora.generate(**input_ids.to(\"cuda\"), do_sample=True, max_length=max_length, temperature=0.75)\n","print(tokenizer.decode(sample_outputs[0], skip_special_tokens=True))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_quant_lora.save()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMtq2mmvd/oOvpXHf2em7Qv","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0568c3a92b8945f695aa9a4e85ecfd30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"056af581ccd54951a2c1ce051864885f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c384f7c1960e4dbca1cde3c84c02203a","placeholder":"â€‹","style":"IPY_MODEL_76c6c865ddf046ec9b343015af5942e8","value":" 1000/1000 [00:07&lt;00:00, 141.29 examples/s]"}},"08ba6059e4034035b9c340312e445126":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"091ac2d262df418a9ebf848cb466a41a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0963cfb5da384ebdaca4987775a9f8dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_de3228afd342412194bd6f3437caabe9","max":332126737,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85c17482227c4885b26c5c572fbe4403","value":332126737}},"0a1c1bef17d64e65af54e6856b002c82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c24a48672a443dc8d795a997dd1c7cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cf0941f196e4f3ca7cc75517dcb1f55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd8bce12867841d2829caa7756934065","IPY_MODEL_483f7158923d4f62af290999b38d2d38","IPY_MODEL_cb0aa040b0e14f61bd2ed60f744b1dd6"],"layout":"IPY_MODEL_08ba6059e4034035b9c340312e445126"}},"119208558aa14cbd96fea30459864e86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c804189eb67645248622da5e33ec4b82","IPY_MODEL_1d6cc12599d145038b4bdffb24087075","IPY_MODEL_6a9c7325fbe04dd08724e2a2cd3863f8"],"layout":"IPY_MODEL_44e9da26e4ba439b9fa79bab3ea14973"}},"15f89022d5814a05b797d0e731e78302":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1668a1f5ed4b460fb7a55fbd7e7cd187":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d6cc12599d145038b4bdffb24087075":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2ff74387fb34072a15925eb52690c90","max":464322921,"min":0,"orientation":"horizontal","style":"IPY_MODEL_36f35c92f90d48d69085463c42a13145","value":464322921}},"21ddc1c7c3ed482c818dece93b7dc4a8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26eb30a908344f3ea2e5f5c2b51fd4d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"282d081302e74ebc8a8102a26d0cb810":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29b7cdcc83334b5486a7cd7adc25384c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d52f5a67ca448e9a5beb652163d988c","placeholder":"â€‹","style":"IPY_MODEL_543078f0e1a4445bae450622c2744cea","value":" 332M/332M [00:48&lt;00:00, 5.04MB/s]"}},"2de738e0d1c34312b97ab47a3b186d63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93e22a4de7c24ba3a227a8266ad98512","IPY_MODEL_a20b470994e84cd095eb2a794d3cf555","IPY_MODEL_8864770497994a05842f9014aa61d1d1"],"layout":"IPY_MODEL_62fd8035170a4349b7294c0462b04887"}},"3108797ecb624f1b8851fe1123ae20f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a453e8fe88544a96a6f17dc4aaf28751","IPY_MODEL_0963cfb5da384ebdaca4987775a9f8dd","IPY_MODEL_29b7cdcc83334b5486a7cd7adc25384c"],"layout":"IPY_MODEL_aa4856bb4e0c4f4f962272b730c4d600"}},"32c95063fa85431ca4fa53676152ca12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34d4a947cb1f431681a7ad5a54934ef9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"351b34630ed44b24b0487ed296ed32c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36f35c92f90d48d69085463c42a13145":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d52f5a67ca448e9a5beb652163d988c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44e9da26e4ba439b9fa79bab3ea14973":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46b2506b2a944b85b975722b5f6ca9c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"483f7158923d4f62af290999b38d2d38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34d4a947cb1f431681a7ad5a54934ef9","max":209,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b7a868f7d4484c9a82c2c4edf9adf7fc","value":209}},"50b076cf68404aef8d4c36e4a3126965":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_899e7020138e4777a44c523e267dbd49","placeholder":"â€‹","style":"IPY_MODEL_bfe2b33bc7e44c4b88132eee3bf6467e","value":"Map: 100%"}},"543078f0e1a4445bae450622c2744cea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55edb259dd304b60a4bab01c4594fafa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b60cc4d07d64990947e483958d82daf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62fd8035170a4349b7294c0462b04887":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a9c7325fbe04dd08724e2a2cd3863f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eadc5249aa054173a91b089d668e0eb4","placeholder":"â€‹","style":"IPY_MODEL_8d4929845807488d9d61e69002b3e206","value":" 464M/464M [01:03&lt;00:00, 7.88MB/s]"}},"74a2482f9c4a445cb993f7c7b77db665":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76c6c865ddf046ec9b343015af5942e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7768b6a6d57f429dae37b3844716b0df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8410d3b5ef33477d957615481972689b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_282d081302e74ebc8a8102a26d0cb810","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_88d330b952764d5f8a32a019a502ade8","value":1000}},"85c17482227c4885b26c5c572fbe4403":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"876c4bbc756348fba803e81b7dcb3068":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8864770497994a05842f9014aa61d1d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_993990f8d53d465099ab3292f783da8b","placeholder":"â€‹","style":"IPY_MODEL_1668a1f5ed4b460fb7a55fbd7e7cd187","value":" 1/1 [01:52&lt;00:00, 112.58s/it]"}},"88d330b952764d5f8a32a019a502ade8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"899e7020138e4777a44c523e267dbd49":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d4929845807488d9d61e69002b3e206":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93e22a4de7c24ba3a227a8266ad98512":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d01be107e0cf49059cf5337a298e689f","placeholder":"â€‹","style":"IPY_MODEL_c7f4a3980e4d4bc29cf0009e560fb2d5","value":"Downloading data files: 100%"}},"97065343d7d64abe813feeae2fee3f22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"993990f8d53d465099ab3292f783da8b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b587012d3df4db68a7ad20706589b29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c251fa642b045f38ea19170ff1d6efa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f29993e9dd404a3dbe0e46953bcebff6","IPY_MODEL_c404db34d6d34632930bcd76b7bf93ec","IPY_MODEL_b6f13ac34bc64e67ada6a35a3538747d"],"layout":"IPY_MODEL_46b2506b2a944b85b975722b5f6ca9c8"}},"9f16c094169d407f803e25241954fa12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c24a48672a443dc8d795a997dd1c7cc","placeholder":"â€‹","style":"IPY_MODEL_9b587012d3df4db68a7ad20706589b29","value":"Extracting data files: 100%"}},"a12f7e2adb3a4d0283fcad5428f89d01":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a20b470994e84cd095eb2a794d3cf555":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7768b6a6d57f429dae37b3844716b0df","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0568c3a92b8945f695aa9a4e85ecfd30","value":1}},"a357b437beb442c0a36fe0939b178950":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f16c094169d407f803e25241954fa12","IPY_MODEL_a407b7af7986428a8009878878881979","IPY_MODEL_dc52c99e332d4ecca83882d9a2284384"],"layout":"IPY_MODEL_ab39267f24f84dec98baeaec29030e70"}},"a407b7af7986428a8009878878881979":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eecddc61db504faaba850c24842a8ff7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_351b34630ed44b24b0487ed296ed32c3","value":1}},"a453e8fe88544a96a6f17dc4aaf28751":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74a2482f9c4a445cb993f7c7b77db665","placeholder":"â€‹","style":"IPY_MODEL_aa3839d0edfb4585849e5e8f71a73665","value":"Downloading data: 100%"}},"a7a4fd93f3934cc59c6f5105a5198de8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa3839d0edfb4585849e5e8f71a73665":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa4856bb4e0c4f4f962272b730c4d600":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab39267f24f84dec98baeaec29030e70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b37a0b1c2cff47c4b7434811a99c3348":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6f13ac34bc64e67ada6a35a3538747d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdf3dfdf7ce647cab407f5958402ed6a","placeholder":"â€‹","style":"IPY_MODEL_26eb30a908344f3ea2e5f5c2b51fd4d1","value":" 120675/0 [00:10&lt;00:00, 12234.06 examples/s]"}},"b7a868f7d4484c9a82c2c4edf9adf7fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bfe2b33bc7e44c4b88132eee3bf6467e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c384f7c1960e4dbca1cde3c84c02203a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c404db34d6d34632930bcd76b7bf93ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97065343d7d64abe813feeae2fee3f22","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b37a0b1c2cff47c4b7434811a99c3348","value":1}},"c7f4a3980e4d4bc29cf0009e560fb2d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c804189eb67645248622da5e33ec4b82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b60cc4d07d64990947e483958d82daf","placeholder":"â€‹","style":"IPY_MODEL_0a1c1bef17d64e65af54e6856b002c82","value":"Downloading data: 100%"}},"cb0aa040b0e14f61bd2ed60f744b1dd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_091ac2d262df418a9ebf848cb466a41a","placeholder":"â€‹","style":"IPY_MODEL_15f89022d5814a05b797d0e731e78302","value":" 209/209 [00:00&lt;00:00, 12.7kB/s]"}},"cdf3dfdf7ce647cab407f5958402ed6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d01be107e0cf49059cf5337a298e689f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc52c99e332d4ecca83882d9a2284384":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55edb259dd304b60a4bab01c4594fafa","placeholder":"â€‹","style":"IPY_MODEL_e6c2702a41524c42bbe360d0aa70bd1b","value":" 1/1 [00:00&lt;00:00, 42.73it/s]"}},"dd8bce12867841d2829caa7756934065":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32c95063fa85431ca4fa53676152ca12","placeholder":"â€‹","style":"IPY_MODEL_876c4bbc756348fba803e81b7dcb3068","value":"Downloading readme: 100%"}},"de3228afd342412194bd6f3437caabe9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2991bdeab924f499e160304b1b81ec1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50b076cf68404aef8d4c36e4a3126965","IPY_MODEL_8410d3b5ef33477d957615481972689b","IPY_MODEL_056af581ccd54951a2c1ce051864885f"],"layout":"IPY_MODEL_21ddc1c7c3ed482c818dece93b7dc4a8"}},"e2ff74387fb34072a15925eb52690c90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6c2702a41524c42bbe360d0aa70bd1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eadc5249aa054173a91b089d668e0eb4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eecddc61db504faaba850c24842a8ff7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f29993e9dd404a3dbe0e46953bcebff6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a12f7e2adb3a4d0283fcad5428f89d01","placeholder":"â€‹","style":"IPY_MODEL_a7a4fd93f3934cc59c6f5105a5198de8","value":"Generating train split: "}}}}},"nbformat":4,"nbformat_minor":0}
